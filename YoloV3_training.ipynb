{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of yolo_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjbnOVR1S4OKwWiAojeWyt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "udU4IVPmqC9Q"
      },
      "source": [
        "import config\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from model import YOLOv3\n",
        "from tqdm import tqdm\n",
        "from utils import (mean_average_precision,\n",
        "                   cells_to_bboxes,\n",
        "                   get_evaluation_bboxes,\n",
        "                   save_checkpoint,\n",
        "                   load_checkpoint,\n",
        "                   check_class_accuracy,\n",
        "                   get_loaders,\n",
        "                   plot_couple_examples)\n",
        "from loss import YoloLoss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-GV1sXJqGy_"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "def train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    losses = []\n",
        "    for batch_idx, (x, y) in enumerate(loop):\n",
        "        x = x.to(config.DEVICE)\n",
        "        y0, y1, y2 = (y[0].to(config.DEVICE),\n",
        "                      y[1].to(config.DEVICE),\n",
        "                      y[2].to(config.DEVICE))\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            out = model(x)\n",
        "            loss = (loss_fn(out[0], y0, scaled_anchors[0])\n",
        "                + loss_fn(out[1], y1, scaled_anchors[1])\n",
        "                + loss_fn(out[2], y2, scaled_anchors[2]))\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        mean_loss = sum(losses) / len(losses)\n",
        "        loop.set_postfix(loss=mean_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "FUuxiVNmqiUB",
        "outputId": "27be6bd6-ddb2-4374-d182-a37e94c5bed0"
      },
      "source": [
        "def main():\n",
        "    model = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
        "    loss_fn = YoloLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    train_loader, test_loader, train_eval_loader = get_loaders(train_csv_path=config.DATASET + \"/8examples.csv\" , test_csv_path=config.DATASET + \"/8examples.csv\")   #\"/train.csv\"   #\"/test.csv\" \n",
        "\n",
        "    if config.LOAD_MODEL:\n",
        "        load_checkpoint(config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE)\n",
        "\n",
        "    scaled_anchors = (torch.tensor(config.ANCHORS)* torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)).to(config.DEVICE)\n",
        "\n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors)\n",
        "\n",
        "        if config.SAVE_MODEL:\n",
        "          save_checkpoint(model, optimizer)\n",
        "\n",
        "        if epoch > 0 and epoch % 10 == 0:\n",
        "            check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)\n",
        "            pred_boxes, true_boxes = get_evaluation_bboxes(test_loader, model, iou_threshold=config.NMS_IOU_THRESH, anchors=config.ANCHORS, threshold=config.CONF_THRESHOLD)\n",
        "            \n",
        "            mapval = mean_average_precision(pred_boxes, true_boxes, iou_threshold=config.MAP_IOU_THRESH, box_format=\"midpoint\", num_classes=config.NUM_CLASSES)\n",
        "        \n",
        "            print(f\"MAP: {mapval.item()}\")\n",
        "            model.train()\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "    main()  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1a1ffb2dd5c5>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    main()\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CBbUzXmrIS1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}