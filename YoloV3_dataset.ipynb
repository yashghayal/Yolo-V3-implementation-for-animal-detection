{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of yolo_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlJy0OIRe9El89dWRP56RD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld1gIogPtcXQ"
      },
      "source": [
        "import config\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfQx7zSctp8s"
      },
      "source": [
        "from PIL import Image, ImageFile\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from utils import (iou_width_height as iou,\n",
        "                   non_max_suppression as nms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL2-zehjuWGM"
      },
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdhxluqC3Uv6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "fde1c762-f207-4aca-c5d7-a3799eebbf22"
      },
      "source": [
        "class YOLODataset(Dataset):\n",
        "  def __init__(self, csv_file, img_dir, label_dir, anchors, image_size = 416, S = [13, 26, 52], C = 20, transform = None):\n",
        "    self.annotations = pd.read_csv(csv_file)\n",
        "    self.img_dir = img_dir\n",
        "    self.label_dir = label_dir\n",
        "    self.transform = transform\n",
        "    self.S = S\n",
        "    self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])\n",
        "    self.num_anchors = self.anchors.shape[0]\n",
        "    self.num_anchors_per_scale = self.num_anchors/3\n",
        "    self.C = C\n",
        "    self.ignore_iou_thresh = 0.5\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1])\n",
        "    bboxes = np.roll(np.loadtxt(fname = label_path, delimiter = \" \", ndmin = 2), 4, axis = 1).tolist()\n",
        "    img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
        "    image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "\n",
        "    if self.transform:\n",
        "      augmentations = self.transform(image = image, bboxes = bboxes)\n",
        "      image = augmentations[\"image\"]\n",
        "      bboxes = augmentations[\"bboxes\"]\n",
        "\n",
        "    targets = [torch.zeros((self.num_anchors/3, S, S, 6)) for S in self.S]\n",
        "\n",
        "    for box in bboxes:\n",
        "      iou_anchors = iou(torch.tensor(box[2:4]), self.anchors)\n",
        "      anchor_indices = iou_anchors.argsort(descending = True, dim = 0)\n",
        "      x, y, width, height, class_label = box\n",
        "      has_anchor = [False, False, False]\n",
        "\n",
        "      for anchor_idx in anchor_indices:\n",
        "        scale_idx = anchor_idx/ self.num_anchors_per_scale\n",
        "        anchor_on_scale = anchor_idx % self.num_anchors_per_scale\n",
        "        S = self.S[scale_idx]\n",
        "        i, j = int(S*y), int(S*x)\n",
        "        anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n",
        "\n",
        "        if not anchor_taken and not has_anchor[scale_idx]:\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n",
        "          x_cell, y_cell = S*x - j , S*y - i\n",
        "          width_cell, height_cell = (width*S, height*S)\n",
        "\n",
        "          box_coordinates = torch.tensor([x_cell, y_cell, width_cell, height_cell])\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 5] = int(class_label)\n",
        "          has_anchor[scale_idx] = True\n",
        "\n",
        "        elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n",
        "          targets[scale_idx][anchor_on_scale, i, j, 0] = -1\n",
        "          \n",
        "\n",
        "    return image, tuple(targets)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1906aef4500f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m52\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLiksUGbdYb0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}